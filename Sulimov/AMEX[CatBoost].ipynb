{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556705fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad14ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'C:\\Users\\danys\\Downloads\\data_compressed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b1de56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb31c86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D_145'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = df.columns.to_list()\n",
    "df_columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4430640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.008771</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.009217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.009827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  0.938469   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  0.936665   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  0.954180   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13  0.960384   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771  0.004709  ...   \n",
       "1  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798  0.002714  ...   \n",
       "2  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598  0.009423  ...   \n",
       "3  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685  0.005531  ...   \n",
       "4  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653  0.009312  ...   \n",
       "\n",
       "   D_136  D_137  D_138     D_139     D_140     D_141  D_142     D_143  \\\n",
       "0    NaN    NaN    NaN  0.002427  0.003706  0.003818    NaN  0.000569   \n",
       "1    NaN    NaN    NaN  0.003954  0.003167  0.005032    NaN  0.009576   \n",
       "2    NaN    NaN    NaN  0.003269  0.007329  0.000427    NaN  0.003429   \n",
       "3    NaN    NaN    NaN  0.006117  0.004516  0.003200    NaN  0.008419   \n",
       "4    NaN    NaN    NaN  0.003671  0.004946  0.008889    NaN  0.001670   \n",
       "\n",
       "      D_144     D_145  \n",
       "0  0.000610  0.002674  \n",
       "1  0.005492  0.009217  \n",
       "2  0.006986  0.002603  \n",
       "3  0.006527  0.009600  \n",
       "4  0.008126  0.009827  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b688ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "num_features = [col for col in df if col not in cat_features + ['S_2', 'customer_ID', 'B_31', 'D_87']]\n",
    "binary_features = ['B_31', 'D_87']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c93e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df.iloc[:15000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2606b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb9b8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_num = sampled_df.groupby('customer_ID')[num_features].agg(['mean', 'median', 'max', 'min', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a55658",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_cat = sampled_df.groupby('customer_ID')[cat_features].agg(['count', 'nunique'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f00aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 897)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danys\\AppData\\Local\\Temp/ipykernel_2844/4085544773.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_features_sharp = df_features.drop('customer_ID', axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.concat([aggregated_cat, aggregated_num], axis=1)\n",
    "df_features.reset_index(inplace=True)\n",
    "df_features_sharp = df_features.drop('customer_ID', axis=1)\n",
    "print(df_features_sharp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e837f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">B_30</th>\n",
       "      <th colspan=\"2\" halign=\"left\">B_38</th>\n",
       "      <th colspan=\"2\" halign=\"left\">D_114</th>\n",
       "      <th colspan=\"2\" halign=\"left\">D_116</th>\n",
       "      <th colspan=\"2\" halign=\"left\">D_117</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">D_144</th>\n",
       "      <th colspan=\"5\" halign=\"left\">D_145</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>nunique</th>\n",
       "      <th>count</th>\n",
       "      <th>nunique</th>\n",
       "      <th>count</th>\n",
       "      <th>nunique</th>\n",
       "      <th>count</th>\n",
       "      <th>nunique</th>\n",
       "      <th>count</th>\n",
       "      <th>nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.002729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.003406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.003426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 897 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   B_30          B_38         D_114         D_116         D_117          ...  \\\n",
       "  count nunique count nunique count nunique count nunique count nunique  ...   \n",
       "0    13       1    13       1    13       1    13       1    13       1  ...   \n",
       "1    13       1    13       1    13       1    13       1    13       1  ...   \n",
       "2    13       1    13       1    13       2    13       1    13       1  ...   \n",
       "3    13       1    13       1    13       1    13       1    13       2  ...   \n",
       "4    13       1    13       2    13       1    13       1    13       1  ...   \n",
       "\n",
       "      D_144                                             D_145            \\\n",
       "       mean    median       max       min       std      mean    median   \n",
       "0  0.005283  0.005492  0.009616  0.000610  0.002598  0.005814  0.006362   \n",
       "1  0.004218  0.003169  0.009568  0.000027  0.002871  0.004902  0.004469   \n",
       "2  0.005113  0.004747  0.009415  0.000129  0.003638  0.004500  0.005110   \n",
       "3  0.004768  0.004793  0.009919  0.000492  0.002654  0.005236  0.006356   \n",
       "4  0.004380  0.004070  0.009436  0.000633  0.002633  0.004219  0.002884   \n",
       "\n",
       "                                 \n",
       "        max       min       std  \n",
       "0  0.009827  0.000995  0.003294  \n",
       "1  0.009390  0.000796  0.002729  \n",
       "2  0.006932  0.000443  0.002152  \n",
       "3  0.009836  0.000029  0.003406  \n",
       "4  0.009666  0.000083  0.003426  \n",
       "\n",
       "[5 rows x 897 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_sharp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ec9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(r\"C:\\Users\\danys\\Downloads\\train_new\\train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e987879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_sharp = train_labels.iloc[:1251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86af5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features_sharp\n",
    "y = train_labels_sharp.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2a188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2581c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danys\\AppData\\Local\\Temp/ipykernel_2844/2102111229.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X_train, X_test = X_train.drop('index', axis=1), X_test.drop('index', axis=1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .30, random_state=42)\n",
    "X_train, X_test = X_train.reset_index(), X_test.reset_index()  # that's done for the sake of starting from 0\n",
    "X_train, X_test = X_train.drop('index', axis=1), X_test.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25bf4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    class_weight={0: 0.20,1: 1.},\n",
    "    oob_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e93b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features_sharp\n",
    "y = train_labels_sharp.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dd963ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "908179b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp = imp.transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab5b8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_imp, y_train)\n",
    "y_pred = model.predict(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79bd3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test_imp)[:, model.classes_[model.classes_ == 1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b67f5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf = pd.DataFrame(\n",
    "        {\"scores\" : [model.oob_score_, model.score(X_test_imp, y_test), roc_auc_score(y_test, y_pred_proba), f1_score(y_test, y_pred)]},\n",
    "        index = [\"oob_score\", \"accuracy\", \"roc_auc\", \"f1_score\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79507ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>oob_score</th>\n",
       "      <td>0.865143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.864362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.935883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.715084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "oob_score  0.865143\n",
       "accuracy   0.864362\n",
       "roc_auc    0.935883\n",
       "f1_score   0.715084"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1341f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 0', 'class 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a7caed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.90      0.92      0.91       283\n",
      "     class 1       0.74      0.69      0.72        93\n",
      "\n",
      "    accuracy                           0.86       376\n",
      "   macro avg       0.82      0.81      0.81       376\n",
      "weighted avg       0.86      0.86      0.86       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "535612ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a8f7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ccf5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_regression = LogisticRegressionCV(random_state=42,\n",
    "                       penalty = 'l1', class_weight= {0: 0.2, 1:1}, cv=5,\n",
    "                                            solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9ed33a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\danys\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(class_weight={0: 0.2, 1: 1}, cv=5, penalty='l1',\n",
       "                     random_state=42, solver='saga')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_regression.fit(X_train_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a134062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_log = model_log_regression.predict(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4104f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_proba_log = model_log_regression.predict_proba(X_test_imp)[:, model_log_regression.classes_[model_log_regression.classes_ == 1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3342c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_log = pd.DataFrame(\n",
    "        {roc_auc_score(y_test, predictions_proba_log), f1_score(y_test, preds_log)},\n",
    "        index = [\"roc_auc\", \"f1-score\"], columns=['result']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f3b783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.928721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.710744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            result\n",
       "roc_auc   0.928721\n",
       "f1-score  0.710744"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b611e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.97      0.78      0.86       283\n",
      "     class 1       0.58      0.92      0.71        93\n",
      "\n",
      "    accuracy                           0.81       376\n",
      "   macro avg       0.77      0.85      0.79       376\n",
      "weighted avg       0.87      0.81      0.83       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_log, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a157ba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.1.1-cp39-none-win_amd64.whl (74.0 MB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\danys\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\danys\\anaconda3\\lib\\site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\danys\\anaconda3\\lib\\site-packages (from catboost) (3.4.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\danys\\anaconda3\\lib\\site-packages (from catboost) (5.11.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\danys\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.1.0)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.1.1 graphviz-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3e9e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf9dc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(\n",
    "    iterations=3000,\n",
    "    learning_rate=0.02,\n",
    "    depth=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8d5f958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af5c02b595b4861ab3b704b7a85ecd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6742055\ttest: 0.6735661\tbest: 0.6735661 (0)\ttotal: 131ms\tremaining: 6m 32s\n",
      "1:\tlearn: 0.6588808\ttest: 0.6588550\tbest: 0.6588550 (1)\ttotal: 157ms\tremaining: 3m 55s\n",
      "2:\tlearn: 0.6464841\ttest: 0.6462668\tbest: 0.6462668 (2)\ttotal: 183ms\tremaining: 3m 2s\n",
      "3:\tlearn: 0.6312492\ttest: 0.6303104\tbest: 0.6303104 (3)\ttotal: 208ms\tremaining: 2m 35s\n",
      "4:\tlearn: 0.6213965\ttest: 0.6211578\tbest: 0.6211578 (4)\ttotal: 234ms\tremaining: 2m 19s\n",
      "5:\tlearn: 0.6070953\ttest: 0.6065418\tbest: 0.6065418 (5)\ttotal: 255ms\tremaining: 2m 7s\n",
      "6:\tlearn: 0.5961852\ttest: 0.5950321\tbest: 0.5950321 (6)\ttotal: 276ms\tremaining: 1m 57s\n",
      "7:\tlearn: 0.5817437\ttest: 0.5811099\tbest: 0.5811099 (7)\ttotal: 294ms\tremaining: 1m 49s\n",
      "8:\tlearn: 0.5706754\ttest: 0.5691505\tbest: 0.5691505 (8)\ttotal: 311ms\tremaining: 1m 43s\n",
      "9:\tlearn: 0.5606787\ttest: 0.5603178\tbest: 0.5603178 (9)\ttotal: 329ms\tremaining: 1m 38s\n",
      "10:\tlearn: 0.5497129\ttest: 0.5484309\tbest: 0.5484309 (10)\ttotal: 345ms\tremaining: 1m 33s\n",
      "11:\tlearn: 0.5424327\ttest: 0.5410806\tbest: 0.5410806 (11)\ttotal: 360ms\tremaining: 1m 29s\n",
      "12:\tlearn: 0.5322826\ttest: 0.5296856\tbest: 0.5296856 (12)\ttotal: 388ms\tremaining: 1m 29s\n",
      "13:\tlearn: 0.5222422\ttest: 0.5202292\tbest: 0.5202292 (13)\ttotal: 415ms\tremaining: 1m 28s\n",
      "14:\tlearn: 0.5130817\ttest: 0.5113431\tbest: 0.5113431 (14)\ttotal: 439ms\tremaining: 1m 27s\n",
      "15:\tlearn: 0.5055083\ttest: 0.5043485\tbest: 0.5043485 (15)\ttotal: 461ms\tremaining: 1m 25s\n",
      "16:\tlearn: 0.4987967\ttest: 0.4970654\tbest: 0.4970654 (16)\ttotal: 480ms\tremaining: 1m 24s\n",
      "17:\tlearn: 0.4904360\ttest: 0.4888470\tbest: 0.4888470 (17)\ttotal: 498ms\tremaining: 1m 22s\n",
      "18:\tlearn: 0.4847245\ttest: 0.4821436\tbest: 0.4821436 (18)\ttotal: 518ms\tremaining: 1m 21s\n",
      "19:\tlearn: 0.4767643\ttest: 0.4747054\tbest: 0.4747054 (19)\ttotal: 536ms\tremaining: 1m 19s\n",
      "20:\tlearn: 0.4695022\ttest: 0.4669599\tbest: 0.4669599 (20)\ttotal: 551ms\tremaining: 1m 18s\n",
      "21:\tlearn: 0.4621183\ttest: 0.4603466\tbest: 0.4603466 (21)\ttotal: 566ms\tremaining: 1m 16s\n",
      "22:\tlearn: 0.4555697\ttest: 0.4546306\tbest: 0.4546306 (22)\ttotal: 581ms\tremaining: 1m 15s\n",
      "23:\tlearn: 0.4482886\ttest: 0.4486010\tbest: 0.4486010 (23)\ttotal: 596ms\tremaining: 1m 13s\n",
      "24:\tlearn: 0.4413426\ttest: 0.4418642\tbest: 0.4418642 (24)\ttotal: 610ms\tremaining: 1m 12s\n",
      "25:\tlearn: 0.4347200\ttest: 0.4350948\tbest: 0.4350948 (25)\ttotal: 624ms\tremaining: 1m 11s\n",
      "26:\tlearn: 0.4296605\ttest: 0.4302218\tbest: 0.4302218 (26)\ttotal: 638ms\tremaining: 1m 10s\n",
      "27:\tlearn: 0.4245955\ttest: 0.4253281\tbest: 0.4253281 (27)\ttotal: 653ms\tremaining: 1m 9s\n",
      "28:\tlearn: 0.4195807\ttest: 0.4200691\tbest: 0.4200691 (28)\ttotal: 667ms\tremaining: 1m 8s\n",
      "29:\tlearn: 0.4144612\ttest: 0.4158015\tbest: 0.4158015 (29)\ttotal: 682ms\tremaining: 1m 7s\n",
      "30:\tlearn: 0.4102439\ttest: 0.4113842\tbest: 0.4113842 (30)\ttotal: 696ms\tremaining: 1m 6s\n",
      "31:\tlearn: 0.4059134\ttest: 0.4076856\tbest: 0.4076856 (31)\ttotal: 711ms\tremaining: 1m 5s\n",
      "32:\tlearn: 0.4019792\ttest: 0.4043557\tbest: 0.4043557 (32)\ttotal: 727ms\tremaining: 1m 5s\n",
      "33:\tlearn: 0.3979670\ttest: 0.4011089\tbest: 0.4011089 (33)\ttotal: 747ms\tremaining: 1m 5s\n",
      "34:\tlearn: 0.3927343\ttest: 0.3963529\tbest: 0.3963529 (34)\ttotal: 763ms\tremaining: 1m 4s\n",
      "35:\tlearn: 0.3873898\ttest: 0.3915076\tbest: 0.3915076 (35)\ttotal: 778ms\tremaining: 1m 4s\n",
      "36:\tlearn: 0.3822985\ttest: 0.3866142\tbest: 0.3866142 (36)\ttotal: 792ms\tremaining: 1m 3s\n",
      "37:\tlearn: 0.3792274\ttest: 0.3838989\tbest: 0.3838989 (37)\ttotal: 806ms\tremaining: 1m 2s\n",
      "38:\tlearn: 0.3753772\ttest: 0.3804654\tbest: 0.3804654 (38)\ttotal: 821ms\tremaining: 1m 2s\n",
      "39:\tlearn: 0.3710202\ttest: 0.3776012\tbest: 0.3776012 (39)\ttotal: 836ms\tremaining: 1m 1s\n",
      "40:\tlearn: 0.3674444\ttest: 0.3740692\tbest: 0.3740692 (40)\ttotal: 850ms\tremaining: 1m 1s\n",
      "41:\tlearn: 0.3646991\ttest: 0.3715376\tbest: 0.3715376 (41)\ttotal: 867ms\tremaining: 1m 1s\n",
      "42:\tlearn: 0.3627383\ttest: 0.3696102\tbest: 0.3696102 (42)\ttotal: 881ms\tremaining: 1m\n",
      "43:\tlearn: 0.3594401\ttest: 0.3660912\tbest: 0.3660912 (43)\ttotal: 896ms\tremaining: 1m\n",
      "44:\tlearn: 0.3563116\ttest: 0.3640426\tbest: 0.3640426 (44)\ttotal: 910ms\tremaining: 59.8s\n",
      "45:\tlearn: 0.3532950\ttest: 0.3618255\tbest: 0.3618255 (45)\ttotal: 926ms\tremaining: 59.5s\n",
      "46:\tlearn: 0.3506090\ttest: 0.3595540\tbest: 0.3595540 (46)\ttotal: 944ms\tremaining: 59.3s\n",
      "47:\tlearn: 0.3477188\ttest: 0.3565140\tbest: 0.3565140 (47)\ttotal: 959ms\tremaining: 59s\n",
      "48:\tlearn: 0.3450819\ttest: 0.3538716\tbest: 0.3538716 (48)\ttotal: 974ms\tremaining: 58.6s\n",
      "49:\tlearn: 0.3426434\ttest: 0.3514519\tbest: 0.3514519 (49)\ttotal: 988ms\tremaining: 58.3s\n",
      "50:\tlearn: 0.3397429\ttest: 0.3485664\tbest: 0.3485664 (50)\ttotal: 1s\tremaining: 58s\n",
      "51:\tlearn: 0.3373645\ttest: 0.3468033\tbest: 0.3468033 (51)\ttotal: 1.02s\tremaining: 57.7s\n",
      "52:\tlearn: 0.3345417\ttest: 0.3445274\tbest: 0.3445274 (52)\ttotal: 1.03s\tremaining: 57.4s\n",
      "53:\tlearn: 0.3325397\ttest: 0.3429148\tbest: 0.3429148 (53)\ttotal: 1.05s\tremaining: 57.4s\n",
      "54:\tlearn: 0.3300228\ttest: 0.3405369\tbest: 0.3405369 (54)\ttotal: 1.07s\tremaining: 57.3s\n",
      "55:\tlearn: 0.3281193\ttest: 0.3386956\tbest: 0.3386956 (55)\ttotal: 1.09s\tremaining: 57.1s\n",
      "56:\tlearn: 0.3261083\ttest: 0.3370561\tbest: 0.3370561 (56)\ttotal: 1.1s\tremaining: 56.9s\n",
      "57:\tlearn: 0.3240233\ttest: 0.3355359\tbest: 0.3355359 (57)\ttotal: 1.12s\tremaining: 56.7s\n",
      "58:\tlearn: 0.3217203\ttest: 0.3341218\tbest: 0.3341218 (58)\ttotal: 1.13s\tremaining: 56.5s\n",
      "59:\tlearn: 0.3197588\ttest: 0.3321675\tbest: 0.3321675 (59)\ttotal: 1.16s\tremaining: 56.6s\n",
      "60:\tlearn: 0.3175299\ttest: 0.3308209\tbest: 0.3308209 (60)\ttotal: 1.17s\tremaining: 56.4s\n",
      "61:\tlearn: 0.3159556\ttest: 0.3297223\tbest: 0.3297223 (61)\ttotal: 1.19s\tremaining: 56.2s\n",
      "62:\tlearn: 0.3141485\ttest: 0.3282178\tbest: 0.3282178 (62)\ttotal: 1.2s\tremaining: 56s\n",
      "63:\tlearn: 0.3119894\ttest: 0.3263982\tbest: 0.3263982 (63)\ttotal: 1.22s\tremaining: 55.8s\n",
      "64:\tlearn: 0.3099438\ttest: 0.3247938\tbest: 0.3247938 (64)\ttotal: 1.23s\tremaining: 55.6s\n",
      "65:\tlearn: 0.3081183\ttest: 0.3234532\tbest: 0.3234532 (65)\ttotal: 1.25s\tremaining: 55.4s\n",
      "66:\tlearn: 0.3060980\ttest: 0.3217263\tbest: 0.3217263 (66)\ttotal: 1.26s\tremaining: 55.2s\n",
      "67:\tlearn: 0.3040110\ttest: 0.3200720\tbest: 0.3200720 (67)\ttotal: 1.28s\tremaining: 55.1s\n",
      "68:\tlearn: 0.3022910\ttest: 0.3191957\tbest: 0.3191957 (68)\ttotal: 1.29s\tremaining: 54.9s\n",
      "69:\tlearn: 0.3005082\ttest: 0.3181435\tbest: 0.3181435 (69)\ttotal: 1.31s\tremaining: 54.8s\n",
      "70:\tlearn: 0.2992115\ttest: 0.3170034\tbest: 0.3170034 (70)\ttotal: 1.32s\tremaining: 54.6s\n",
      "71:\tlearn: 0.2983207\ttest: 0.3169334\tbest: 0.3169334 (71)\ttotal: 1.34s\tremaining: 54.5s\n",
      "72:\tlearn: 0.2967576\ttest: 0.3160662\tbest: 0.3160662 (72)\ttotal: 1.35s\tremaining: 54.3s\n",
      "73:\tlearn: 0.2954739\ttest: 0.3151568\tbest: 0.3151568 (73)\ttotal: 1.37s\tremaining: 54.3s\n",
      "74:\tlearn: 0.2936448\ttest: 0.3137421\tbest: 0.3137421 (74)\ttotal: 1.39s\tremaining: 54.1s\n",
      "75:\tlearn: 0.2921098\ttest: 0.3122718\tbest: 0.3122718 (75)\ttotal: 1.4s\tremaining: 54s\n",
      "76:\tlearn: 0.2907271\ttest: 0.3115034\tbest: 0.3115034 (76)\ttotal: 1.42s\tremaining: 53.9s\n",
      "77:\tlearn: 0.2895673\ttest: 0.3107742\tbest: 0.3107742 (77)\ttotal: 1.43s\tremaining: 53.7s\n",
      "78:\tlearn: 0.2880103\ttest: 0.3096271\tbest: 0.3096271 (78)\ttotal: 1.45s\tremaining: 53.6s\n",
      "79:\tlearn: 0.2865008\ttest: 0.3087537\tbest: 0.3087537 (79)\ttotal: 1.46s\tremaining: 53.4s\n",
      "80:\tlearn: 0.2854350\ttest: 0.3078449\tbest: 0.3078449 (80)\ttotal: 1.48s\tremaining: 53.3s\n",
      "81:\tlearn: 0.2839261\ttest: 0.3069647\tbest: 0.3069647 (81)\ttotal: 1.49s\tremaining: 53.2s\n",
      "82:\tlearn: 0.2827924\ttest: 0.3063212\tbest: 0.3063212 (82)\ttotal: 1.51s\tremaining: 53.1s\n",
      "83:\tlearn: 0.2816735\ttest: 0.3055276\tbest: 0.3055276 (83)\ttotal: 1.52s\tremaining: 52.9s\n",
      "84:\tlearn: 0.2799841\ttest: 0.3038148\tbest: 0.3038148 (84)\ttotal: 1.54s\tremaining: 52.8s\n",
      "85:\tlearn: 0.2789446\ttest: 0.3031878\tbest: 0.3031878 (85)\ttotal: 1.56s\tremaining: 52.7s\n",
      "86:\tlearn: 0.2777049\ttest: 0.3024748\tbest: 0.3024748 (86)\ttotal: 1.57s\tremaining: 52.7s\n",
      "87:\tlearn: 0.2767067\ttest: 0.3016269\tbest: 0.3016269 (87)\ttotal: 1.59s\tremaining: 52.6s\n",
      "88:\tlearn: 0.2753913\ttest: 0.3007410\tbest: 0.3007410 (88)\ttotal: 1.6s\tremaining: 52.5s\n",
      "89:\tlearn: 0.2740045\ttest: 0.2997811\tbest: 0.2997811 (89)\ttotal: 1.62s\tremaining: 52.4s\n",
      "90:\tlearn: 0.2731538\ttest: 0.2992260\tbest: 0.2992260 (90)\ttotal: 1.64s\tremaining: 52.3s\n",
      "91:\tlearn: 0.2721541\ttest: 0.2988019\tbest: 0.2988019 (91)\ttotal: 1.65s\tremaining: 52.2s\n",
      "92:\tlearn: 0.2711531\ttest: 0.2980735\tbest: 0.2980735 (92)\ttotal: 1.66s\tremaining: 52s\n",
      "93:\tlearn: 0.2701741\ttest: 0.2978107\tbest: 0.2978107 (93)\ttotal: 1.68s\tremaining: 51.9s\n",
      "94:\tlearn: 0.2687776\ttest: 0.2965412\tbest: 0.2965412 (94)\ttotal: 1.69s\tremaining: 51.8s\n",
      "95:\tlearn: 0.2678676\ttest: 0.2961920\tbest: 0.2961920 (95)\ttotal: 1.71s\tremaining: 51.6s\n",
      "96:\tlearn: 0.2671217\ttest: 0.2955670\tbest: 0.2955670 (96)\ttotal: 1.72s\tremaining: 51.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97:\tlearn: 0.2663322\ttest: 0.2949587\tbest: 0.2949587 (97)\ttotal: 1.74s\tremaining: 51.4s\n",
      "98:\tlearn: 0.2652996\ttest: 0.2941392\tbest: 0.2941392 (98)\ttotal: 1.75s\tremaining: 51.4s\n",
      "99:\tlearn: 0.2642030\ttest: 0.2933445\tbest: 0.2933445 (99)\ttotal: 1.77s\tremaining: 51.2s\n",
      "100:\tlearn: 0.2632127\ttest: 0.2928929\tbest: 0.2928929 (100)\ttotal: 1.78s\tremaining: 51.1s\n",
      "101:\tlearn: 0.2624352\ttest: 0.2924033\tbest: 0.2924033 (101)\ttotal: 1.79s\tremaining: 51s\n",
      "102:\tlearn: 0.2613707\ttest: 0.2919646\tbest: 0.2919646 (102)\ttotal: 1.81s\tremaining: 50.9s\n",
      "103:\tlearn: 0.2602762\ttest: 0.2918726\tbest: 0.2918726 (103)\ttotal: 1.82s\tremaining: 50.8s\n",
      "104:\tlearn: 0.2594108\ttest: 0.2917438\tbest: 0.2917438 (104)\ttotal: 1.84s\tremaining: 50.7s\n",
      "105:\tlearn: 0.2586417\ttest: 0.2912813\tbest: 0.2912813 (105)\ttotal: 1.85s\tremaining: 50.6s\n",
      "106:\tlearn: 0.2572897\ttest: 0.2902616\tbest: 0.2902616 (106)\ttotal: 1.87s\tremaining: 50.5s\n",
      "107:\tlearn: 0.2563807\ttest: 0.2898746\tbest: 0.2898746 (107)\ttotal: 1.88s\tremaining: 50.4s\n",
      "108:\tlearn: 0.2552192\ttest: 0.2894521\tbest: 0.2894521 (108)\ttotal: 1.9s\tremaining: 50.3s\n",
      "109:\tlearn: 0.2546171\ttest: 0.2894691\tbest: 0.2894521 (108)\ttotal: 1.91s\tremaining: 50.2s\n",
      "110:\tlearn: 0.2538727\ttest: 0.2891822\tbest: 0.2891822 (110)\ttotal: 1.93s\tremaining: 50.1s\n",
      "111:\tlearn: 0.2530884\ttest: 0.2887122\tbest: 0.2887122 (111)\ttotal: 1.94s\tremaining: 50.1s\n",
      "112:\tlearn: 0.2523710\ttest: 0.2883126\tbest: 0.2883126 (112)\ttotal: 1.96s\tremaining: 50.1s\n",
      "113:\tlearn: 0.2515361\ttest: 0.2881146\tbest: 0.2881146 (113)\ttotal: 1.98s\tremaining: 50.1s\n",
      "114:\tlearn: 0.2506369\ttest: 0.2879198\tbest: 0.2879198 (114)\ttotal: 1.99s\tremaining: 50s\n",
      "115:\tlearn: 0.2496095\ttest: 0.2873361\tbest: 0.2873361 (115)\ttotal: 2.01s\tremaining: 49.9s\n",
      "116:\tlearn: 0.2487302\ttest: 0.2870675\tbest: 0.2870675 (116)\ttotal: 2.02s\tremaining: 49.9s\n",
      "117:\tlearn: 0.2479898\ttest: 0.2866398\tbest: 0.2866398 (117)\ttotal: 2.04s\tremaining: 49.8s\n",
      "118:\tlearn: 0.2472616\ttest: 0.2859704\tbest: 0.2859704 (118)\ttotal: 2.05s\tremaining: 49.7s\n",
      "119:\tlearn: 0.2465996\ttest: 0.2856223\tbest: 0.2856223 (119)\ttotal: 2.07s\tremaining: 49.6s\n",
      "120:\tlearn: 0.2460127\ttest: 0.2854086\tbest: 0.2854086 (120)\ttotal: 2.08s\tremaining: 49.6s\n",
      "121:\tlearn: 0.2453406\ttest: 0.2851552\tbest: 0.2851552 (121)\ttotal: 2.1s\tremaining: 49.5s\n",
      "122:\tlearn: 0.2445892\ttest: 0.2847331\tbest: 0.2847331 (122)\ttotal: 2.11s\tremaining: 49.4s\n",
      "123:\tlearn: 0.2438428\ttest: 0.2844068\tbest: 0.2844068 (123)\ttotal: 2.13s\tremaining: 49.4s\n",
      "124:\tlearn: 0.2430933\ttest: 0.2841697\tbest: 0.2841697 (124)\ttotal: 2.14s\tremaining: 49.3s\n",
      "125:\tlearn: 0.2424683\ttest: 0.2840026\tbest: 0.2840026 (125)\ttotal: 2.16s\tremaining: 49.3s\n",
      "126:\tlearn: 0.2418807\ttest: 0.2841004\tbest: 0.2840026 (125)\ttotal: 2.18s\tremaining: 49.3s\n",
      "127:\tlearn: 0.2413470\ttest: 0.2840011\tbest: 0.2840011 (127)\ttotal: 2.19s\tremaining: 49.2s\n",
      "128:\tlearn: 0.2409221\ttest: 0.2837092\tbest: 0.2837092 (128)\ttotal: 2.21s\tremaining: 49.1s\n",
      "129:\tlearn: 0.2403266\ttest: 0.2837105\tbest: 0.2837092 (128)\ttotal: 2.22s\tremaining: 49.1s\n",
      "130:\tlearn: 0.2395671\ttest: 0.2833458\tbest: 0.2833458 (130)\ttotal: 2.24s\tremaining: 49s\n",
      "131:\tlearn: 0.2388868\ttest: 0.2831969\tbest: 0.2831969 (131)\ttotal: 2.25s\tremaining: 49s\n",
      "132:\tlearn: 0.2382927\ttest: 0.2831593\tbest: 0.2831593 (132)\ttotal: 2.27s\tremaining: 48.9s\n",
      "133:\tlearn: 0.2375574\ttest: 0.2827166\tbest: 0.2827166 (133)\ttotal: 2.28s\tremaining: 48.9s\n",
      "134:\tlearn: 0.2368836\ttest: 0.2827372\tbest: 0.2827166 (133)\ttotal: 2.3s\tremaining: 48.8s\n",
      "135:\tlearn: 0.2364596\ttest: 0.2826156\tbest: 0.2826156 (135)\ttotal: 2.31s\tremaining: 48.7s\n",
      "136:\tlearn: 0.2358271\ttest: 0.2822956\tbest: 0.2822956 (136)\ttotal: 2.33s\tremaining: 48.7s\n",
      "137:\tlearn: 0.2351488\ttest: 0.2821897\tbest: 0.2821897 (137)\ttotal: 2.34s\tremaining: 48.6s\n",
      "138:\tlearn: 0.2344184\ttest: 0.2820778\tbest: 0.2820778 (138)\ttotal: 2.36s\tremaining: 48.6s\n",
      "139:\tlearn: 0.2338785\ttest: 0.2816815\tbest: 0.2816815 (139)\ttotal: 2.38s\tremaining: 48.5s\n",
      "140:\tlearn: 0.2333128\ttest: 0.2812261\tbest: 0.2812261 (140)\ttotal: 2.39s\tremaining: 48.5s\n",
      "141:\tlearn: 0.2325680\ttest: 0.2813212\tbest: 0.2812261 (140)\ttotal: 2.41s\tremaining: 48.4s\n",
      "142:\tlearn: 0.2320524\ttest: 0.2811081\tbest: 0.2811081 (142)\ttotal: 2.42s\tremaining: 48.4s\n",
      "143:\tlearn: 0.2312840\ttest: 0.2812006\tbest: 0.2811081 (142)\ttotal: 2.44s\tremaining: 48.3s\n",
      "144:\tlearn: 0.2307595\ttest: 0.2810838\tbest: 0.2810838 (144)\ttotal: 2.45s\tremaining: 48.3s\n",
      "145:\tlearn: 0.2302304\ttest: 0.2807623\tbest: 0.2807623 (145)\ttotal: 2.47s\tremaining: 48.2s\n",
      "146:\tlearn: 0.2299230\ttest: 0.2806530\tbest: 0.2806530 (146)\ttotal: 2.48s\tremaining: 48.2s\n",
      "147:\tlearn: 0.2294506\ttest: 0.2806693\tbest: 0.2806530 (146)\ttotal: 2.5s\tremaining: 48.1s\n",
      "148:\tlearn: 0.2287172\ttest: 0.2805960\tbest: 0.2805960 (148)\ttotal: 2.51s\tremaining: 48.1s\n",
      "149:\tlearn: 0.2279027\ttest: 0.2806424\tbest: 0.2805960 (148)\ttotal: 2.53s\tremaining: 48s\n",
      "150:\tlearn: 0.2273361\ttest: 0.2804190\tbest: 0.2804190 (150)\ttotal: 2.54s\tremaining: 48s\n",
      "151:\tlearn: 0.2267940\ttest: 0.2803512\tbest: 0.2803512 (151)\ttotal: 2.56s\tremaining: 48s\n",
      "152:\tlearn: 0.2261231\ttest: 0.2803907\tbest: 0.2803512 (151)\ttotal: 2.58s\tremaining: 47.9s\n",
      "153:\tlearn: 0.2258158\ttest: 0.2802672\tbest: 0.2802672 (153)\ttotal: 2.59s\tremaining: 47.9s\n",
      "154:\tlearn: 0.2253629\ttest: 0.2803033\tbest: 0.2802672 (153)\ttotal: 2.6s\tremaining: 47.8s\n",
      "155:\tlearn: 0.2250394\ttest: 0.2803172\tbest: 0.2802672 (153)\ttotal: 2.62s\tremaining: 47.8s\n",
      "156:\tlearn: 0.2245765\ttest: 0.2800804\tbest: 0.2800804 (156)\ttotal: 2.63s\tremaining: 47.7s\n",
      "157:\tlearn: 0.2242970\ttest: 0.2799967\tbest: 0.2799967 (157)\ttotal: 2.65s\tremaining: 47.7s\n",
      "158:\tlearn: 0.2237650\ttest: 0.2800443\tbest: 0.2799967 (157)\ttotal: 2.67s\tremaining: 47.7s\n",
      "159:\tlearn: 0.2232226\ttest: 0.2798910\tbest: 0.2798910 (159)\ttotal: 2.68s\tremaining: 47.6s\n",
      "160:\tlearn: 0.2226219\ttest: 0.2793130\tbest: 0.2793130 (160)\ttotal: 2.7s\tremaining: 47.6s\n",
      "161:\tlearn: 0.2220074\ttest: 0.2792612\tbest: 0.2792612 (161)\ttotal: 2.71s\tremaining: 47.5s\n",
      "162:\tlearn: 0.2216814\ttest: 0.2791622\tbest: 0.2791622 (162)\ttotal: 2.73s\tremaining: 47.5s\n",
      "163:\tlearn: 0.2212442\ttest: 0.2791404\tbest: 0.2791404 (163)\ttotal: 2.74s\tremaining: 47.4s\n",
      "164:\tlearn: 0.2206038\ttest: 0.2789143\tbest: 0.2789143 (164)\ttotal: 2.76s\tremaining: 47.4s\n",
      "165:\tlearn: 0.2200463\ttest: 0.2789164\tbest: 0.2789143 (164)\ttotal: 2.77s\tremaining: 47.3s\n",
      "166:\tlearn: 0.2196591\ttest: 0.2787073\tbest: 0.2787073 (166)\ttotal: 2.79s\tremaining: 47.3s\n",
      "167:\tlearn: 0.2194088\ttest: 0.2786627\tbest: 0.2786627 (167)\ttotal: 2.8s\tremaining: 47.2s\n",
      "168:\tlearn: 0.2187205\ttest: 0.2786174\tbest: 0.2786174 (168)\ttotal: 2.82s\tremaining: 47.2s\n",
      "169:\tlearn: 0.2184506\ttest: 0.2786946\tbest: 0.2786174 (168)\ttotal: 2.83s\tremaining: 47.1s\n",
      "170:\tlearn: 0.2173147\ttest: 0.2783601\tbest: 0.2783601 (170)\ttotal: 2.85s\tremaining: 47.1s\n",
      "171:\tlearn: 0.2167826\ttest: 0.2780218\tbest: 0.2780218 (171)\ttotal: 2.87s\tremaining: 47.1s\n",
      "172:\tlearn: 0.2161739\ttest: 0.2779372\tbest: 0.2779372 (172)\ttotal: 2.88s\tremaining: 47.1s\n",
      "173:\tlearn: 0.2156681\ttest: 0.2779269\tbest: 0.2779269 (173)\ttotal: 2.9s\tremaining: 47.1s\n",
      "174:\tlearn: 0.2150980\ttest: 0.2781063\tbest: 0.2779269 (173)\ttotal: 2.91s\tremaining: 47s\n",
      "175:\tlearn: 0.2144138\ttest: 0.2777473\tbest: 0.2777473 (175)\ttotal: 2.93s\tremaining: 47s\n",
      "176:\tlearn: 0.2138843\ttest: 0.2775389\tbest: 0.2775389 (176)\ttotal: 2.95s\tremaining: 47s\n",
      "177:\tlearn: 0.2134086\ttest: 0.2772494\tbest: 0.2772494 (177)\ttotal: 2.96s\tremaining: 47s\n",
      "178:\tlearn: 0.2129978\ttest: 0.2768790\tbest: 0.2768790 (178)\ttotal: 2.98s\tremaining: 46.9s\n",
      "179:\tlearn: 0.2125423\ttest: 0.2768341\tbest: 0.2768341 (179)\ttotal: 2.99s\tremaining: 46.9s\n",
      "180:\tlearn: 0.2118469\ttest: 0.2766033\tbest: 0.2766033 (180)\ttotal: 3.01s\tremaining: 46.8s\n",
      "181:\tlearn: 0.2114500\ttest: 0.2765033\tbest: 0.2765033 (181)\ttotal: 3.02s\tremaining: 46.8s\n",
      "182:\tlearn: 0.2109948\ttest: 0.2764840\tbest: 0.2764840 (182)\ttotal: 3.04s\tremaining: 46.7s\n",
      "183:\tlearn: 0.2105030\ttest: 0.2763967\tbest: 0.2763967 (183)\ttotal: 3.05s\tremaining: 46.7s\n",
      "184:\tlearn: 0.2100543\ttest: 0.2765913\tbest: 0.2763967 (183)\ttotal: 3.07s\tremaining: 46.7s\n",
      "185:\tlearn: 0.2094721\ttest: 0.2765774\tbest: 0.2763967 (183)\ttotal: 3.08s\tremaining: 46.7s\n",
      "186:\tlearn: 0.2090855\ttest: 0.2765633\tbest: 0.2763967 (183)\ttotal: 3.11s\tremaining: 46.8s\n",
      "187:\tlearn: 0.2086332\ttest: 0.2761000\tbest: 0.2761000 (187)\ttotal: 3.13s\tremaining: 46.8s\n",
      "188:\tlearn: 0.2080508\ttest: 0.2755539\tbest: 0.2755539 (188)\ttotal: 3.15s\tremaining: 46.9s\n",
      "189:\tlearn: 0.2077613\ttest: 0.2752742\tbest: 0.2752742 (189)\ttotal: 3.17s\tremaining: 46.9s\n",
      "190:\tlearn: 0.2073440\ttest: 0.2751851\tbest: 0.2751851 (190)\ttotal: 3.19s\tremaining: 46.9s\n",
      "191:\tlearn: 0.2070180\ttest: 0.2751058\tbest: 0.2751058 (191)\ttotal: 3.2s\tremaining: 46.9s\n",
      "192:\tlearn: 0.2066626\ttest: 0.2751334\tbest: 0.2751058 (191)\ttotal: 3.22s\tremaining: 46.8s\n",
      "193:\tlearn: 0.2062502\ttest: 0.2747843\tbest: 0.2747843 (193)\ttotal: 3.23s\tremaining: 46.8s\n",
      "194:\tlearn: 0.2057644\ttest: 0.2749445\tbest: 0.2747843 (193)\ttotal: 3.25s\tremaining: 46.7s\n",
      "195:\tlearn: 0.2051855\ttest: 0.2744637\tbest: 0.2744637 (195)\ttotal: 3.26s\tremaining: 46.7s\n",
      "196:\tlearn: 0.2047076\ttest: 0.2744951\tbest: 0.2744637 (195)\ttotal: 3.28s\tremaining: 46.6s\n",
      "197:\tlearn: 0.2042737\ttest: 0.2743715\tbest: 0.2743715 (197)\ttotal: 3.29s\tremaining: 46.6s\n",
      "198:\tlearn: 0.2038331\ttest: 0.2738463\tbest: 0.2738463 (198)\ttotal: 3.31s\tremaining: 46.6s\n",
      "199:\tlearn: 0.2034029\ttest: 0.2736177\tbest: 0.2736177 (199)\ttotal: 3.33s\tremaining: 46.6s\n",
      "200:\tlearn: 0.2028409\ttest: 0.2735383\tbest: 0.2735383 (200)\ttotal: 3.34s\tremaining: 46.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201:\tlearn: 0.2023658\ttest: 0.2734241\tbest: 0.2734241 (201)\ttotal: 3.36s\tremaining: 46.5s\n",
      "202:\tlearn: 0.2020805\ttest: 0.2734558\tbest: 0.2734241 (201)\ttotal: 3.38s\tremaining: 46.5s\n",
      "203:\tlearn: 0.2018402\ttest: 0.2733479\tbest: 0.2733479 (203)\ttotal: 3.39s\tremaining: 46.5s\n",
      "204:\tlearn: 0.2012407\ttest: 0.2734227\tbest: 0.2733479 (203)\ttotal: 3.41s\tremaining: 46.5s\n",
      "205:\tlearn: 0.2008413\ttest: 0.2732527\tbest: 0.2732527 (205)\ttotal: 3.43s\tremaining: 46.5s\n",
      "206:\tlearn: 0.2004861\ttest: 0.2731682\tbest: 0.2731682 (206)\ttotal: 3.44s\tremaining: 46.4s\n",
      "207:\tlearn: 0.2000263\ttest: 0.2731535\tbest: 0.2731535 (207)\ttotal: 3.46s\tremaining: 46.4s\n",
      "208:\tlearn: 0.1995633\ttest: 0.2731170\tbest: 0.2731170 (208)\ttotal: 3.48s\tremaining: 46.4s\n",
      "209:\tlearn: 0.1991298\ttest: 0.2730658\tbest: 0.2730658 (209)\ttotal: 3.49s\tremaining: 46.4s\n",
      "210:\tlearn: 0.1987258\ttest: 0.2730263\tbest: 0.2730263 (210)\ttotal: 3.51s\tremaining: 46.4s\n",
      "211:\tlearn: 0.1983606\ttest: 0.2729673\tbest: 0.2729673 (211)\ttotal: 3.52s\tremaining: 46.3s\n",
      "212:\tlearn: 0.1981339\ttest: 0.2730165\tbest: 0.2729673 (211)\ttotal: 3.54s\tremaining: 46.3s\n",
      "213:\tlearn: 0.1977330\ttest: 0.2726538\tbest: 0.2726538 (213)\ttotal: 3.56s\tremaining: 46.3s\n",
      "214:\tlearn: 0.1971174\ttest: 0.2723779\tbest: 0.2723779 (214)\ttotal: 3.58s\tremaining: 46.3s\n",
      "215:\tlearn: 0.1967413\ttest: 0.2722057\tbest: 0.2722057 (215)\ttotal: 3.6s\tremaining: 46.3s\n",
      "216:\tlearn: 0.1964193\ttest: 0.2720952\tbest: 0.2720952 (216)\ttotal: 3.61s\tremaining: 46.3s\n",
      "217:\tlearn: 0.1959182\ttest: 0.2719316\tbest: 0.2719316 (217)\ttotal: 3.63s\tremaining: 46.3s\n",
      "218:\tlearn: 0.1955562\ttest: 0.2717580\tbest: 0.2717580 (218)\ttotal: 3.65s\tremaining: 46.3s\n",
      "219:\tlearn: 0.1952698\ttest: 0.2718203\tbest: 0.2717580 (218)\ttotal: 3.66s\tremaining: 46.3s\n",
      "220:\tlearn: 0.1949068\ttest: 0.2719093\tbest: 0.2717580 (218)\ttotal: 3.68s\tremaining: 46.2s\n",
      "221:\tlearn: 0.1943966\ttest: 0.2717370\tbest: 0.2717370 (221)\ttotal: 3.69s\tremaining: 46.2s\n",
      "222:\tlearn: 0.1942626\ttest: 0.2716769\tbest: 0.2716769 (222)\ttotal: 3.71s\tremaining: 46.2s\n",
      "223:\tlearn: 0.1936870\ttest: 0.2716033\tbest: 0.2716033 (223)\ttotal: 3.73s\tremaining: 46.2s\n",
      "224:\tlearn: 0.1933892\ttest: 0.2714935\tbest: 0.2714935 (224)\ttotal: 3.74s\tremaining: 46.2s\n",
      "225:\tlearn: 0.1928513\ttest: 0.2715437\tbest: 0.2714935 (224)\ttotal: 3.76s\tremaining: 46.1s\n",
      "226:\tlearn: 0.1924861\ttest: 0.2712135\tbest: 0.2712135 (226)\ttotal: 3.78s\tremaining: 46.1s\n",
      "227:\tlearn: 0.1924087\ttest: 0.2711600\tbest: 0.2711600 (227)\ttotal: 3.79s\tremaining: 46.1s\n",
      "228:\tlearn: 0.1921786\ttest: 0.2711404\tbest: 0.2711404 (228)\ttotal: 3.81s\tremaining: 46.1s\n",
      "229:\tlearn: 0.1916960\ttest: 0.2709144\tbest: 0.2709144 (229)\ttotal: 3.82s\tremaining: 46s\n",
      "230:\tlearn: 0.1911647\ttest: 0.2706688\tbest: 0.2706688 (230)\ttotal: 3.83s\tremaining: 46s\n",
      "231:\tlearn: 0.1905979\ttest: 0.2704838\tbest: 0.2704838 (231)\ttotal: 3.85s\tremaining: 45.9s\n",
      "232:\tlearn: 0.1902001\ttest: 0.2706259\tbest: 0.2704838 (231)\ttotal: 3.87s\tremaining: 45.9s\n",
      "233:\tlearn: 0.1898462\ttest: 0.2705035\tbest: 0.2704838 (231)\ttotal: 3.88s\tremaining: 45.9s\n",
      "234:\tlearn: 0.1895303\ttest: 0.2703161\tbest: 0.2703161 (234)\ttotal: 3.9s\tremaining: 45.8s\n",
      "235:\tlearn: 0.1891040\ttest: 0.2701911\tbest: 0.2701911 (235)\ttotal: 3.91s\tremaining: 45.8s\n",
      "236:\tlearn: 0.1887759\ttest: 0.2699569\tbest: 0.2699569 (236)\ttotal: 3.93s\tremaining: 45.8s\n",
      "237:\tlearn: 0.1885262\ttest: 0.2699076\tbest: 0.2699076 (237)\ttotal: 3.94s\tremaining: 45.7s\n",
      "238:\tlearn: 0.1883114\ttest: 0.2698251\tbest: 0.2698251 (238)\ttotal: 3.96s\tremaining: 45.7s\n",
      "239:\tlearn: 0.1881684\ttest: 0.2698004\tbest: 0.2698004 (239)\ttotal: 3.97s\tremaining: 45.7s\n",
      "240:\tlearn: 0.1877551\ttest: 0.2700810\tbest: 0.2698004 (239)\ttotal: 3.99s\tremaining: 45.7s\n",
      "241:\tlearn: 0.1874387\ttest: 0.2702384\tbest: 0.2698004 (239)\ttotal: 4s\tremaining: 45.6s\n",
      "242:\tlearn: 0.1870654\ttest: 0.2700042\tbest: 0.2698004 (239)\ttotal: 4.02s\tremaining: 45.6s\n",
      "243:\tlearn: 0.1867239\ttest: 0.2701656\tbest: 0.2698004 (239)\ttotal: 4.03s\tremaining: 45.6s\n",
      "244:\tlearn: 0.1864147\ttest: 0.2702554\tbest: 0.2698004 (239)\ttotal: 4.05s\tremaining: 45.5s\n",
      "245:\tlearn: 0.1859571\ttest: 0.2702295\tbest: 0.2698004 (239)\ttotal: 4.07s\tremaining: 45.5s\n",
      "246:\tlearn: 0.1857580\ttest: 0.2701191\tbest: 0.2698004 (239)\ttotal: 4.08s\tremaining: 45.5s\n",
      "247:\tlearn: 0.1853506\ttest: 0.2700883\tbest: 0.2698004 (239)\ttotal: 4.09s\tremaining: 45.4s\n",
      "248:\tlearn: 0.1851321\ttest: 0.2700323\tbest: 0.2698004 (239)\ttotal: 4.11s\tremaining: 45.4s\n",
      "249:\tlearn: 0.1848645\ttest: 0.2697967\tbest: 0.2697967 (249)\ttotal: 4.13s\tremaining: 45.4s\n",
      "250:\tlearn: 0.1846094\ttest: 0.2696797\tbest: 0.2696797 (250)\ttotal: 4.14s\tremaining: 45.3s\n",
      "251:\tlearn: 0.1843717\ttest: 0.2697270\tbest: 0.2696797 (250)\ttotal: 4.15s\tremaining: 45.3s\n",
      "252:\tlearn: 0.1840216\ttest: 0.2697178\tbest: 0.2696797 (250)\ttotal: 4.17s\tremaining: 45.3s\n",
      "253:\tlearn: 0.1835696\ttest: 0.2699330\tbest: 0.2696797 (250)\ttotal: 4.19s\tremaining: 45.3s\n",
      "254:\tlearn: 0.1831812\ttest: 0.2700352\tbest: 0.2696797 (250)\ttotal: 4.2s\tremaining: 45.2s\n",
      "255:\tlearn: 0.1825274\ttest: 0.2702943\tbest: 0.2696797 (250)\ttotal: 4.22s\tremaining: 45.2s\n",
      "256:\tlearn: 0.1822357\ttest: 0.2702614\tbest: 0.2696797 (250)\ttotal: 4.24s\tremaining: 45.2s\n",
      "257:\tlearn: 0.1820046\ttest: 0.2701303\tbest: 0.2696797 (250)\ttotal: 4.25s\tremaining: 45.2s\n",
      "258:\tlearn: 0.1816007\ttest: 0.2702500\tbest: 0.2696797 (250)\ttotal: 4.27s\tremaining: 45.2s\n",
      "259:\tlearn: 0.1812682\ttest: 0.2701030\tbest: 0.2696797 (250)\ttotal: 4.28s\tremaining: 45.1s\n",
      "260:\tlearn: 0.1807820\ttest: 0.2702523\tbest: 0.2696797 (250)\ttotal: 4.3s\tremaining: 45.1s\n",
      "261:\tlearn: 0.1805307\ttest: 0.2702204\tbest: 0.2696797 (250)\ttotal: 4.31s\tremaining: 45.1s\n",
      "262:\tlearn: 0.1801073\ttest: 0.2704192\tbest: 0.2696797 (250)\ttotal: 4.33s\tremaining: 45s\n",
      "263:\tlearn: 0.1796481\ttest: 0.2707196\tbest: 0.2696797 (250)\ttotal: 4.34s\tremaining: 45s\n",
      "264:\tlearn: 0.1793240\ttest: 0.2706173\tbest: 0.2696797 (250)\ttotal: 4.36s\tremaining: 45s\n",
      "265:\tlearn: 0.1789798\ttest: 0.2705144\tbest: 0.2696797 (250)\ttotal: 4.37s\tremaining: 44.9s\n",
      "266:\tlearn: 0.1785963\ttest: 0.2703780\tbest: 0.2696797 (250)\ttotal: 4.39s\tremaining: 44.9s\n",
      "267:\tlearn: 0.1782691\ttest: 0.2705041\tbest: 0.2696797 (250)\ttotal: 4.4s\tremaining: 44.9s\n",
      "268:\tlearn: 0.1778933\ttest: 0.2706530\tbest: 0.2696797 (250)\ttotal: 4.42s\tremaining: 44.9s\n",
      "269:\tlearn: 0.1775309\ttest: 0.2708099\tbest: 0.2696797 (250)\ttotal: 4.43s\tremaining: 44.8s\n",
      "270:\tlearn: 0.1770064\ttest: 0.2707472\tbest: 0.2696797 (250)\ttotal: 4.45s\tremaining: 44.8s\n",
      "271:\tlearn: 0.1768111\ttest: 0.2706991\tbest: 0.2696797 (250)\ttotal: 4.46s\tremaining: 44.8s\n",
      "272:\tlearn: 0.1765729\ttest: 0.2705927\tbest: 0.2696797 (250)\ttotal: 4.48s\tremaining: 44.7s\n",
      "273:\tlearn: 0.1762449\ttest: 0.2708494\tbest: 0.2696797 (250)\ttotal: 4.49s\tremaining: 44.7s\n",
      "274:\tlearn: 0.1757595\ttest: 0.2708538\tbest: 0.2696797 (250)\ttotal: 4.51s\tremaining: 44.7s\n",
      "275:\tlearn: 0.1752839\ttest: 0.2708979\tbest: 0.2696797 (250)\ttotal: 4.52s\tremaining: 44.6s\n",
      "276:\tlearn: 0.1748990\ttest: 0.2707189\tbest: 0.2696797 (250)\ttotal: 4.54s\tremaining: 44.6s\n",
      "277:\tlearn: 0.1746483\ttest: 0.2706656\tbest: 0.2696797 (250)\ttotal: 4.56s\tremaining: 44.6s\n",
      "278:\tlearn: 0.1742627\ttest: 0.2705853\tbest: 0.2696797 (250)\ttotal: 4.58s\tremaining: 44.6s\n",
      "279:\tlearn: 0.1738745\ttest: 0.2703561\tbest: 0.2696797 (250)\ttotal: 4.6s\tremaining: 44.6s\n",
      "280:\tlearn: 0.1734573\ttest: 0.2703829\tbest: 0.2696797 (250)\ttotal: 4.61s\tremaining: 44.6s\n",
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.2696797088\n",
      "bestIteration = 250\n",
      "\n",
      "Shrink model to first 251 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x19f6314e610>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    plot=\"True\",\n",
    "    early_stopping_rounds=30, \n",
    "    eval_set=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d04ed357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.882979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.935883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.715084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            scores\n",
       "accuracy  0.882979\n",
       "roc_auc   0.935883\n",
       "f1_score  0.715084"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cat = cat.predict(X_test)\n",
    "y_pred_proba_cat = cat.predict_proba(X_test)[:,cat.classes_[cat.classes_ == 1][0]]\n",
    "scores = pd.DataFrame(\n",
    "        {\"scores\" : [ cat.score(X_test, y_test), roc_auc_score(y_test, y_pred_proba), f1_score(y_test, y_pred)]},\n",
    "        index = [ \"accuracy\", \"roc_auc\", \"f1_score\"]\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60e35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
